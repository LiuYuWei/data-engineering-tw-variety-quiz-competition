---

[ 開源資料集 ] 自動化 YouTube 題庫擷取：利用 Gemini 2.5 Flash 打造萬筆規模的台灣綜藝知識數據集

---

---

待在資料集缺乏的台灣，我一直在思考如何有效率地「結構化」那些埋藏在影像中的知識。這篇文章將分享我如何利用 Gemini 2.5 Flash 的強大多模態視覺分析能力，配合 Python 自動化工具，打造出一套「一鍵同步、抓取、分析、上傳」的完整工作流。

---

核心痛點：影像知識的結構化難題
在處理《百變智多星》這類台灣本土知識競賽節目時，我們面臨的挑戰遠比想像中複雜：
海量數據的處理成本：單一播放清單包含近 700 部影片，每部影片約 10–20分鐘，人工標註幾乎是不可能的任務。
傳統 OCR 的侷限性：電視節目的字卡設計花俏，且題目與答案出現的時間點、位置並不固定。傳統 OCR 難以在沒有人工介入的情況下，精準判斷「誰是題目、誰是正確答案」，更難以處理選項內容。
增量更新的邏輯維護：如何建立一套機制，確保系統只針對「新上傳」的影片進行處理，避免重複消耗昂貴的 API 額度與運算資源？

---

系統架構：Gemini 2.5 Flash + Python 自動化工作流
我設計了一套四階段自動化流程，並透過 Makefile 將其整合成標準化指令，實現「無人值守」的資料生產線。
Step 1. 同步基準與增量更新 (Incremental Update)
為了避免重複勞動，腳本啟動時會先執行 sync_baseline.py。
邏輯：從 Hugging Face 下載現有的數據集 Parquet 檔案，讀取已存在的影片 ID 列表。
優勢：這建立了系統的「記憶」，確保我們在處理數百個影片的播放清單時，永遠只會鎖定「尚未數位化」的內容，大幅節省成本。

Step 2. YouTube 播放清單自動化抓取
利用 yt-dlp 的強大功能抓取整個播放清單。
精確過濾：我們不下載龐大的影片檔案，而是抓取 Meta-data。透過 Python 過濾掉「私人影片」、「已刪除影片」以及「直播預告」，確保傳送給 AI 的每一條 URL 都是有效且可讀取的。

Step 3. Gemini 2.5 Flash 的多模態視覺分析
這是整個流程的「大腦」。Gemini 2.5 Flash 的突破在於其驚人的 context window 與原生支持影片解析。
精心設計的 Prompt 策略：

「你現在是一位精準的資料庫管理員。請觀看此影片，精準捕捉所有出現的益智問答題。要求如下： 
輸出為嚴格的 JSON 格式。 
包含 question_number, question, answer。 
將其轉換為對話格式 {"from": "human", "value": "…"}。 
格式規範：全形標點符號、半形英數字。」
視覺理解優勢：AI 不僅是讀文字，它能理解「主持人宣布答案」的瞬間，或是「字卡顏色變化」代表的正誤，這在以往需要複雜的電腦視覺算法才能實現。

Step 4. 自動化合併與推送 (CI/CD for Data)
最後，腳本會將本地產生的新 JSONL 資料與從 Hugging Face 抓回來的舊數據進行 concat（合併）。
資料清洗：自動剔除重複項與空值。
一鍵上傳：利用 huggingface_hub 庫，將更新後的資料集推送到 Hub。這意味著我的數據集永遠保持在最新狀態。

---

成果展示
目前這套工具已經能穩定處理播放清單中剩下的影片，並將總題庫數量推向萬筆規模。這項實驗證實了幾個觀點：
成本效益：Flash 等級的模型在視覺處理上速度極快且價格低廉，適合大規模數據工程。
本土化數據的意義：這類數據集填補了 LLM 在「台灣在地常識」與「綜藝語境」下的訓練空白。
影像即資料：將「非結構化影像」轉化為「可訓練語料」是當前數據工程師的最佳實踐路徑。

---

開源連結
如果您對這個項目感興趣，或者想利用這些台灣本土題目來 Fine-tune 您的模型，歡迎訪問我的數據集頁面：
👉 Simon-Liu/tw-variety-quiz-competition

---

結論
從單純的 Gemini CLI 互動到建構這套複雜的自動化數據集流水線，我深刻體會到：AI 不僅僅是聊天機器人，更是數據工程師的「多模態助理」。 透過簡單的 Python 膠水代碼，我們就能將原本死板、難以檢索的影像內容，轉化為具備商業與研究價值的高品質語料庫。

---